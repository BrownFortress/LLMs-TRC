{
    "model_name": "meta-llama/Llama-2-13b-hf",
    "batch_size": 8,
    "patience": 5,
    "epochs": 100,
    "runs":5,
    "init_weights":false,
    "context": "sentence",
    "desc": "word level, linear layer dual_optimizer",
    "lr1": 1e-4,
    "layers": [{"type":"linear", "in":10240, "out":3}],
    "cls_only": false,
    "dual_optimizer": false,
    "frozen":true
}