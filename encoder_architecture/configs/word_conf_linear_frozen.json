{
    "model_name": "roberta-base",
    "batch_size": 8,
    "patience": 5,
    "epochs": 100,
    "runs":5,
    "init_weights":false,
    "context": "sentence",
    "desc": "word level, linear layer dual_optimizer",
    "lr1": 1e-4,
    "layers": [{"type":"linear", "in":1536, "out":3}],
    "cls_only": false,
    "dual_optimizer": false,
    "frozen":true
}